<html>

<head>
  <title>SLS Audio Recording POC</title>
</head>

<body>

    <h1>PCM to MP3</h1>

    <div class="wrapper">
        <div class="sound-clips">
            <!-- flowplayer will init here -->
        </div>
    </div>

    <div class="record-controls">
        <button id="btnRecord" onclick="onRecord()" disabled>Record</button>
        <button id="btnStop" onclick="onStop()" disabled>Stop</button>
    </div>

    <div id="log" style="width:100%; border:solid thin; margin:8px; padding:4px;">
    </div>

    <link rel="stylesheet" href="app.css">
    <link rel="stylesheet" href="http://releases.flowplayer.org/audio/flowplayer.audio.css">
    <link rel="stylesheet" href="http://releases.flowplayer.org/7.2.4/skin/skin.css">
    <script src="flowplayer.js"></script>
    <script src="flowplayer.hlsjs.light.min.js"></script>
    <script src="flowplayer.audio.min.js"></script>
    <script src="lame.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>

    <script id='init'>

        $(document).ready(function() {
            log('Started');
            requestMikePermission();
        });


    </script>

    <script id='logger'>

        function log(msg) {
            var element = document.querySelector('#log');
            element.innerHTML += msg + "<br>\n";
        }

    </script>


    <script id='UITasks'>
        function renderFlowplayerDiv(src, type) {
            var soundClips = document.querySelector('.sound-clips');

            var clipParent = document.createElement('div')
            var clipContainer = document.createElement('div');

            clipParent.id = Date.now();

            clipParent.appendChild(clipContainer);
            soundClips.appendChild(clipParent);

            flowplayer(clipContainer, {
                audioOnly: true,
                clip: {
                sources: [{
                    type: type,
                    src: src
                    }]
                }
            });

            renderDownloadDiv(clipParent.id, src);

        }

        function renderDownloadDiv(parentId, src) {
            var parent = $('#' + parentId)[0];

            var downloadParentDiv = document.createElement('div');
            var downloadAnchor = document.createElement('a');

            downloadAnchor.download = 'recorded.mp3';
            downloadAnchor.href = src;
            downloadAnchor.innerHTML = 'recorded.mp3';

            downloadParentDiv.appendChild(downloadAnchor);
            parent.appendChild(downloadParentDiv);
        }
    </script>


    <script id='buttonControl'>

        function onRecord() {
            startRecording();
        }

        function onStop() {
            stopRecording();
        }

        function recordButtonControl(enable) {
            var button = $('#btnRecord');

            buttonControl(button, enable, 'Record');
        }

        function stopButtonControl(enable) {
            var button = $('#btnStop');

            buttonControl(button, enable, 'Stop');
        }

        function buttonControl(btn, enable, name) {
            if (enable === 1) {
                btn.removeAttr("disabled");
                log(name + ' button enabled');
            } else {
                btn.attr("disabled", "");
                log(name + ' button disabled');

            }
        }

    </script>


    <script id='recordingTask'>
        var gAudio = null;       //Audio context
        var gAudioSrc = null;    //Audio source
        var gNode = null;        //The audio processor node
        var gEncoder = null;     //The MP3 encoder object
        var gStrmMp3 = [];       //Collection of MP3 buffers
        var gIsRecording = false;
        var gCfg = {             //Encoder configuration
            chnlCt: 1,    //1=mono, 2=stereo
            bufSz: 4096, //input buffer size (bytes), 16bit signed int.
            sampleRate: 44100,//Input sample rate (samples per second)
            bitRate: 128    //Output bit rate (9-128)
        };
        var gPcmCt = 0;          //Total input bytes
        var gMp3Ct = 0;          //Total output bytes

        function requestMikePermission() {
            log('Requesting mike permission');
            var constraints = {audio: true};

            try {
                window.AudioContext = window.AudioContext || window.webkitAudioContext || AudioContext;

                // Some browsers partially implement mediaDevices. We can't just assign an object
                // with getUserMedia as it would overwrite existing properties.
                // Here, we will just add the getUserMedia property if it's missing.
                if (navigator.mediaDevices.getUserMedia === undefined) {
                    navigator.mediaDevices.getUserMedia = function(constraints) {

                    // First get ahold of the legacy getUserMedia, if present
                    var getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia;

                    // Some browsers just don't implement it - return a rejected promise with an error
                    // to keep a consistent interface
                    if (!getUserMedia) {
                      return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
                    }

                    // Otherwise, wrap the call to the old navigator.getUserMedia with a Promise
                    return new Promise(function(resolve, reject) {
                      getUserMedia.call(navigator, constraints, resolve, reject);
                    });
                  }
                }

                if (!(gAudio = new window.AudioContext)) {
                    log("ERR: Unable to create Audio Context");
                } else {
                    navigator.mediaDevices.getUserMedia(constraints).then(onGrantedMikePermission, onDeniedMikePermission).catch(onDeniedMikePermission);
                }



            } catch (ex) {
                log("ERR : Unable to find any audio support");
                gAudio = null;
            }

        }

        function onGrantedMikePermission(stream) {
            log('Granted mike permission');

            if (!(gAudioSrc = gAudio.createMediaStreamSource(stream))) {
                log("ERR: Unable to create audio source");
            } else {
                initMp3Encoder();
                recordButtonControl(1);
            }
        }

        function onDeniedMikePermission() {
            log('Denied mike permission');
        }

        //Create the mp3 encoder object.
        function initMp3Encoder() {

            if (!(gEncoder = new lamejs.Mp3Encoder(gCfg.chnlCt, gCfg.sampleRate, gCfg.bitRate))) {
                log("ERR: Unable to create MP3 encoder.");
            } else {
                log("MP3 encoder created.");
            }
        }

        function startRecording() {
            var creator;

            if (!gAudio) {
                log('ERR: No audio source');
            } else if (!gEncoder) {
                log('ERR: No MP3 encoder');
            } else if (gIsRecording) {
                log('ERR: Already recording');
            } else {

                //Create the audio capture node.
                if (!gNode) {
                    if (!(creator = gAudioSrc.context.createScriptProcessor || gAudioSrc.createJavaScriptNode)) {
                        log("ERR: No processor creator");
                    } else if (!(gNode = creator.call(gAudioSrc.context, gCfg.bufSz, gCfg.chnlCt, gCfg.chnlCt))) {
                        log("ERR: Unable to create processor node.");
                    }
                }

                if (!gNode) {
                    log('ERR: onRecord: No processor node.');
                } else {

                    //Set callbacks, connect the node between the audio source and destination.
                    gNode.onaudioprocess = onAudioProcess;
                    gAudioSrc.connect(gNode);
                    gNode.connect(gAudioSrc.context.destination);

                    //re-init the buffers
                    gStrmMp3 = [];
                    gPcmCt = 0;
                    gMp3Ct = 0;

                    gIsRecording = true;
                    recordButtonControl(0);
                    stopButtonControl(1);
                    log("Start recording");

                }
            }
        }

        function stopRecording() {

            if (!gAudio) {
                log('ERR: No audio');
            } else if (!gAudioSrc) {
                log('ERR: No audio source');
            } else if (!gIsRecording) {
                log('ERR: Not recording');
            } else {

                //Disconnect the node
                gNode.onaudioprocess = null;
                gAudioSrc.disconnect(gNode);
                gNode.disconnect();
                gIsRecording = false;
                //Flush the last mp3 buffer.
                var mp3 = gEncoder.flush();
                if (mp3.length > 0)
                    gStrmMp3.push(mp3);
                //Present the mp3 stream on the page.
                showMp3(gStrmMp3);

                recordButtonControl(1);
                stopButtonControl(0);
                log("Stopped recording");
            }
        }

        //Process a single audio buffer.
        //Input is an array of floating-point samples.
        function onAudioProcess(e) {
            //Cap output stream size
            if (gMp3Ct > 200 * 1000)
                return;

            var inBuf = e.inputBuffer;
            var samples = inBuf.getChannelData(0);
            var sampleCt = samples.length;

            //Convert floating-point to 16bit signed int.
            //This may modify the number of samples.
            var samples16 = convertFloatToInt16(samples);
            if (samples16.length > 0) {
                gPcmCt += samples16.length * 2;
                //Encode PCM to mp3
                var mp3buf = gEncoder.encodeBuffer(samples16);
                var mp3Ct = mp3buf.length;
                if (mp3Ct > 0) {
                    //Add buffer to in-memory output stream.
                    gStrmMp3.push(mp3buf);
                    gMp3Ct += mp3Ct;
                }
            }
        }

        //Convert floating point to 16bit signed int.
        function convertFloatToInt16(inFloat) {
            var sampleCt = inFloat.length;
            var outInt16 = new Int16Array(sampleCt);

            for (var n1 = 0; n1 < sampleCt; n1++) {
                //This is where I can apply waveform modifiers.
                var sample16 = 0x8000 * inFloat[n1];
                //Clamp value to avoid integer overflow, which causes audible pops and clicks.
                sample16 = (sample16 < -32767) ? -32767 : (sample16 > 32767) ? 32767 : sample16;
                outInt16[n1] = sample16;
            }

            return (outInt16);
        }

        //Present the output mp3 stream on the page
        //as a download link and content in the audio control.
        function showMp3(mp3) {
            //Consolidate the collection of MP3 buffers into a single data Blob.
            var blob = new Blob(gStrmMp3, {type: 'audio/mp3'});
            //Create a URL to the blob.
            var url = window.URL.createObjectURL(blob);
            //inializing flowplayer
            renderFlowplayerDiv(url, 'audio/mpeg');

        }

    </script>
</body>

</html>
